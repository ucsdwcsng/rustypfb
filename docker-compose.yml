version: "3.9"
services:
  rustcuda:
    build:
      context: .
      dockerfile: Dockerfile
    image: rust-cuda
    container_name: rust-cuda
    shm_size: '2048m'
    networks:
      - nw
    devices:
      - nvidia.com/gpu=0  

    working_dir: "/root/ProjectDir"
    command: ["tail", "-f", "/dev/null"]    # Specify the command to run when the container starts.

  rustcuda-devel:
    build:
      context: .
      dockerfile: Dockerfile
    image: rust-cuda
    container_name: rust-cuda
    shm_size: '2048m'
    volumes:
      - '/mnt/intA-ssdr0-1tb/srajagopal/:/mnt/intA-ssdr0-1tb/:rw'
      - '/mnt/intB-ssdr0-240gb/srajagopal/:/mnt/intB-ssdr1-240gb/:rw'
      - '/mnt/extC-hddr0-18tb/srajagopal/:/mnt/extC-hddr0-18tb/:rw'
      - '/mnt/s3fs/srajagopal/:/mnt/s3fs/:rw'
      - '/mnt/tmpfs/srajagopal/:/mnt/tmpfs/:rw'    
      - "vscode-config:/root/.vscode-server:rw"
      - ".:/root/channelizer:rw"
    networks:
      - nw
    ports:
      - 127.0.0.1::5901
    devices:
      - nvidia.com/gpu=0      
    deploy:
      resources:
        limits:
          cpus: '48'
          memory: 250G

    working_dir: "/root/channelizer"
    command: ["tail", "-f", "/dev/null"]
    cap_add:
      - SYS_ADMIN

  # pytorch-devel-user:
  #   build:
  #     context: .
  #     dockerfile: pytorch-devel-user.dockerfile
  #   image: my-pytorch-devel-user:latest
  #   container_name: pytorch-devel-user
  #   userns_mode: "keep-id:uid=1000,gid=1000"    
  #   shm_size: '2048m'
  #   volumes:
  #     - '/mnt/intA-hddr0-4tb/srajagopal/:/mnt/intA-hddr0-4tb/:rw'
  #     - '/mnt/intB-hddr1-1tb/srajagopal/:/mnt/intB-hddr1-1tb/:rw'
  #     - '/mnt/intC-ssdr0-2tb/srajagopal/:/mnt/intC-ssdr0-2tb/:rw'
  #     - '/mnt/intD-ssdr0-960gb/srajagopal/:/mnt/intD-ssdr0-960gb/:rw'
  #     - '/mnt/s3fs/srajagopal/:/mnt/s3fs/:rw'
  #     - '/mnt/tmpfs/srajagopal/:/mnt/tmpfs/:rw'    
  #     - "vscode-config:/home/torch/.vscode-server:rw"
  #     - ".:/home/torch/testDir:rw"
  #   networks:
  #     - nw
  #   ports:
  #     - 127.0.0.1::5901
  #   devices:
  #     - nvidia.com/gpu=0    
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '48'
  #         memory: 250G    

  #   working_dir: "/home/torch/testDir"
  #   # command: ["tail", "-f", "/dev/null"]


volumes:
  vscode-config:
    driver: local
networks:
  nw:
    driver: bridge
